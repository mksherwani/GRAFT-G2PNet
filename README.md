# GRAFT-G2PNet
GRAFT-G2PNet: Graph Based Adaptive Feature tuning, Genotype2Phenotype network

# ğŸ§  Graph Neural Network Classifier with Optuna Tuning & Feature Selection

A modular, high-performance **Graph Neural Network (GNN)** classifier using **PyTorch Geometric**, with:

- ğŸ§¬ **Autoencoder-based Feature Selection**
- ğŸ” **Optuna Hyperparameter Optimization**
- ğŸ§  **Dynamic GNN Architectures**
- ğŸ“Š **Visualization & Evaluation**
- ğŸ› ï¸ Command-line control for full pipeline

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€Graph_Classification
    â”œâ”€â”€ config
          â”œâ”€â”€ config.yaml       # Configuration file
    â”œâ”€â”€ data
          â”œâ”€â”€ dataloader.py       # Loads features, labels, creates edge indices
    â”œâ”€â”€ models           
          â”œâ”€â”€ model.py           # Autoencoder and dynamic GNN models
    â”œâ”€â”€ training           
          â”œâ”€â”€ trainer.py          # Training loop and early stopping
          â”œâ”€â”€ tuner.py            # Optuna-based hyperparameter tuning
          â”œâ”€â”€ evaluator.py        # Testing + confusion matrix visualization
    â”œâ”€â”€ utils
          â”œâ”€â”€ utils.py            # Helper functions (AE training, edge gen)
    â”œâ”€â”€ main.py             # Entry point: training / tuning / evaluation
â”œâ”€â”€Updated_MOGCN
â””â”€â”€ README.md           # You're here!
```

---

## âš™ï¸ Installation

```bash
pip install torch torchvision torchaudio
pip install torch-geometric
pip install optuna scikit-learn matplotlib pandas
```

---

## ğŸ§ª Pipeline Overview

### 1. ğŸ”¬ Feature Selection with Autoencoder

High-dimensional genotype features are compressed into a lower-dimensional representation using an Autoencoder.

```python
AutoEncoder(input_dim, hidden_dim, compressed_dim)
```

â¡ï¸ Output: compressed features for GNN input.

---

### 2. ğŸ”— Edge Creation

Edges are formed between genotypes using **Euclidean distance** in feature space.

```python
calculate_closest_distances(df, num_closest=8)
```

â¡ï¸ Keeps only `k` closest connections per node to build sparse graph.

---

### 3. ğŸ§  Dynamic GNN Model

Builds a **flexible GNN** using a sequence of:

- `GCNConv` or `SAGEConv` (chosen per layer)
- Batch normalization
- Dropout + ReLU
- Global mean pooling
- Final classifier layer

```python
DynamicGCN(input_dim, hidden_dims, output_dim, layer_types)
```

---

### 4. ğŸ” Hyperparameter Tuning with Optuna

Optuna searches for the best combination of:

| Hyperparameter | Range / Options           |
|----------------|---------------------------|
| Num Layers     | 2 to 3                    |
| Layer Types    | GCNConv / SAGEConv        |
| Hidden Sizes   | 32 to 96 per layer        |
| Optimizer      | Adam / AdamW / SGD        |
| Learning Rate  | 1e-4 to 1e-1 (log scale)  |
| Weight Decay   | 1e-5 to 1e-1 (log scale)  |
| Edge K         | 3 to 10 (neighbors)       |

Results are logged and visualized per trial.

---

### 5. ğŸ‹ï¸ Training

- Cross-entropy loss
- Accuracy tracking
- Early stopping with patience
- Saves loss/accuracy curves per trial

```bash
python main.py --mode train --f1 <features.txt> --f2 <labels.txt> --epoch 200
```

---

### 6. ğŸ“ˆ Evaluation

- Loads best model
- Evaluates on test set
- Plots confusion matrix and final loss/accuracy curves

```bash
python main.py --mode eval --f1 <features.txt> --f2 <labels.txt>
```

---

## ğŸš€ Command Line Usage

### ğŸ”§ Tune with Optuna

```bash
python main.py --mode tune --f1 path/to/input.txt --f2 path/to/labels.txt --epoch 50
```

### ğŸ‹ï¸ Train Final Model

```bash
python main.py --mode train --f1 path/to/input.txt --f2 path/to/labels.txt --epoch 200
```

### ğŸ“Š Evaluate Model

```bash
python main.py --mode eval --f1 path/to/input.txt --f2 path/to/labels.txt
```

---

## ğŸ“Š Output Visuals

All visualizations are saved in the `outputs/` folder:

- `optuna_trial_X_training_curves.png`
- `final_loss_accuracy.png`
- `final_confusion_matrix.png`

---

## ğŸ’¡ Key Features

- âœ… Autoencoder compresses noisy input features
- âœ… Edges dynamically built from input data
- âœ… GNN layer types selected **per layer**
- âœ… All training / tuning / eval via single CLI
- âœ… Easy to adapt for other graph datasets

---

## ğŸ“š Dependencies

- `torch`, `torch-geometric`
- `optuna`
- `scikit-learn`
- `matplotlib`, `pandas`

---

## ğŸ™Œ Credits

Built with â¤ï¸ using:

- [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/)
- [Optuna](https://optuna.org/)
- [Scikit-learn](https://scikit-learn.org/)
